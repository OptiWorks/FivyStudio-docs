# FivyStudio-docs

Live2D 캐릭터 트래킹 프로그램, 생동감 있는 캐릭터와 함께하는 인터랙티브

---

목차  
[프로젝트 소개](#프로젝트-소개)  
[주요 기능](#주요-기능)  
[기능별 사용법](#기능별-사용법)  
[기술/구현 정보](#기술구현-정보)  
[예시 화면](#예시-화면)  
[문의 및 지원](#문의-및-지원)  

---

# 프로젝트 소개
배경: 사용자가 자신의 캐릭터를 실시간으로 움직이도록 만들어 스트리밍을 쉽게 지원  
목적: 직관적이고 간편한 트래킹 환경 제공, 다양한 Live2D 모델 지원  

주요 장점:  
실시간 얼굴 / 아이템 트래킹  
다양한 Live2D 모델 호환  

대상 사용자: 스트리머, VTuber, 디자이너, 인터랙티브 콘텐츠 제작자  

---

# 주요 기능  
| 기능 | 설명 |  
|------|------|  
| 얼굴 트래킹 | 카메라를 통해 얼굴 움직임 실시간 반영 |  
| 표정/눈동자 연동 | 캐릭터 표정 및 눈동자가 자연스럽게 따라 움직임 |  
| 손/몸 동작 트래킹 | (지원 시) 손과 상체 움직임 인식 |  
| 다양한 모델 지원 | Live2D 모델 파일(.model3.json) 쉽게 불러오기 |  
| 사용자 친화 UI | 직관적인 설정과 간편한 조작 인터페이스 |  

---

# 기능별 사용법  
얼굴 트래킹  
설명: 카메라를 통해 사용자의 얼굴 움직임을 실시간으로 캐릭터에 반영  
사용법: 프로그램 실행 → 카메라 권한 허용 → 얼굴 위치 조정 → 트래킹 시작 버튼 클릭  

표정/눈동자 연동  
설명: 눈 깜빡임, 시선, 입 모양 등 세부 표정 반영  
사용법: 트래킹 시작 후 캐릭터 모델 선택 → 표정 연동 설정 조정  

다양한 모델 불러오기  
설명: 지원하는 Live2D 모델을 쉽게 불러와 트래킹에 적용  
사용법: 모델 파일 선택 → 불러오기 → 모델 위치 / 크기 조정  

아이템 트래킹  
설명: 캐릭터의 움직임을 실시간으로 반영하여 아이템의 움직임을 실시간으로 반영  
사용법: 아이템 추가 -> 불러오기 -> 아이템 크기 / 회전 / 위치 조정  

---

# 기술/구현 정보  
트래킹 기술:  
얼굴 인식: OpenCV / MediaPipe / ARKit  
눈/입 동작 감지: Landmark 기반 실시간 분석  
손/몸 동작: (지원 시) Pose Estimation 활용  
Live2D 연동: Cubism SDK 사용, 모델 데이터(.model3.json) 파싱 및 실시간 애니메이션 반영  
UI/환경: Electron / Qt / Unity 등, 직관적인 인터페이스 제공  
실시간 최적화: GPU 가속, 최소 지연 시간으로 자연스러운 트래킹  

---

# 예시 화면  
트래킹 동작 GIF/스크린샷 첨부  
프로그램 UI 화면, 캐릭터 움직임 예시  

---

# 문의 및 지원  
이메일: example@domain.com  
Discord/Slack 등 커뮤니티 채널 링크  
기능 요청 및 버그 제보 안내  